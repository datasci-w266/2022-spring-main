{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LqUNTvTgb_dx"
   },
   "source": [
    "# Conversion of Contextual to Static Word Representations\n",
    "\n",
    "## Author: Sandip S Panesar\n",
    "\n",
    "### V1. October 2021\n",
    "\n",
    "##### Copy this notebook into Colab and run from there for best results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3684,
     "status": "ok",
     "timestamp": 1635956201336,
     "user": {
      "displayName": "Sandip Panesar",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03744674344979941942"
     },
     "user_tz": 420
    },
    "id": "vS4UIzgVl56n",
    "outputId": "22eaf792-7407-4b52-e7a2-0a52183dd082"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.12.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.1.0)\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.46)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.3.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.7.4.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "#NB: May need to install transformer package first\n",
    "!pip install transformers\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wd000uCBcrIW"
   },
   "source": [
    "**Introduction**\n",
    "\n",
    "A fundamental building block of modern natural language processing (NLP) techniques are high-dimensional mathematical word representations. Though there are numerous ways to mathematically quantify words in text, e.g. frequncy, TF-IDF etc., these methods all have particular drawbacks. An alternative, first described by Mikolov et al. (2013) was to utilize neural models to estimate these word representations in a vector space. This technique resulted in the popular Word2Vec language model, which has been widely adopted and utilized. Models like Word2Vec are trained on a single corpus of text data, and produce single word representations for each word in a corpus vocabulary. These representations are typically 1x200 in dimension, i.e. each word has 200 \"dimensions\" of features that encode its semantic and syntatic properties. Word2Vec can produce word representations with a dimensionality of up to 300. \n",
    "\n",
    "Similar high-dimensional word representations are produced by models such as GloVe (global vectors for word representation), described by Pennington et al. (2014), which is a log-bilinear model which is trained on non-zero entries of a global word-word co-occurrence matrix. \n",
    "\n",
    "Nevertheless, the problem with word representations produced by both of the aforementioned is that they are \"static.\" This means that a single representation is produced for a word, which is consequently a product of the word appearing in *every* vocabulary context. Think about the word \"flies\". Depending upon how its used, it could be a verb or a noun:\n",
    "\n",
    "- **Noun:** There are *flies* in my kitchen.\n",
    "\n",
    "![](https://www.pestworld.org/media/560912/istock_000001759709small_2-flies.jpg?preset=pestFeature1280)\n",
    "\n",
    "- **Verb:** Jane *flies* to London on Tuesday.\n",
    "\n",
    "![](https://media-cldnry.s-nbcnews.com/image/upload/t_fit-2000w,f_auto,q_auto:best/newscms/2020_29/3397778/200717-british-airways-747-al-0858.jpg)\n",
    "\n",
    "Naturally, for certain tasks such as machine translation among many others, a single static word representation may produce inaccuracies and negatively affect performance. \n",
    "\n",
    "**Contextual Language Models**\n",
    "\n",
    "A substantial advancement in NLP came with the introduction of contextualized language models such as the bidirectional encoder representation for transformers (BERT) (Devlin et al. 2018). Since the release of Word2Vec, advances had already been made by creating models that could incorporate syntax, morphology, subwords and subcharacters. Nevertheless, the single biggest performance increase has been conferred by models that can incorporate context. BERT, in particular, is a model that has been first trained on massive text corpora (e.g. Wikipedia) and is designed to produce \"just in time\" word embeddings for tasks that notably include language translation and prediction. By initial training on massive corpora, in its core-state BERT possesses a series of context-agnostic word representation layers that are then fine tuned (NB: \"fine tuned\" in this context refers to a different process than further tweaking an already trained BERT model for performance enhancement in a particular domain or task) by passing a sentence example into it. The resulting output is a sequence of word representations for each word in a sentence that are uniquely influenced by each word in that sentence - i.e. they are contextual word representations. \n",
    "\n",
    "**Contextual language model architectures**\n",
    "\n",
    "![](https://miro.medium.com/max/1348/1*lxd3DCwPKYkjmQb3yfy3Hw.png)\n",
    "\n",
    "**Transformers: The building blocks of contextual language models**\n",
    "\n",
    "![](https://miro.medium.com/max/1400/1*abz_nltyDYtC6ThqNg4O6w.png)\n",
    "\n",
    "**Scaled Dot Product Attention**\n",
    "\n",
    "$$\n",
    "\\mathrm{Attention(Q,K,V) = softmax(\\frac{QK^T}{\\sqrt{n}})V}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JygH6AGqlqri"
   },
   "source": [
    "**Contextualized Sequences of Word Representations from BERT**\n",
    "\n",
    "NB. This notebook and all subsequent examples will use the core BERT-base-uncased model (as a HuggingFace transformer package) to demonstrate the technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248,
     "referenced_widgets": [
      "a17f97492e7d4840857fd45597fb5be6",
      "05a179a1cdc54420b2da841a25c3043c",
      "409a36817c8a4e7f890a3d8bab688e20",
      "a339223d9c1647ceb9a1c5a43003ee95",
      "2cf7b96360ae432ab536b0ac7823b9e2",
      "f654f4f436bd4c49a0a7d065127ce323",
      "a7c1c93f69d34f829cbe9b5b99c3defc",
      "f8c5485b0f804c9991b708b6d1b3a09d",
      "7682e7c82b364d62a9fd9b19c496613f",
      "cd305930f718415180560af0d26d4a00",
      "67c85c93aa584c38b236fc6fdeac5bc1",
      "962625fe6a4e4c5ba2ddf870211eadb0",
      "e54f72015b224ffca8c69735cb481c29",
      "b1afee80bec8444bbcd0052e42ae07ec",
      "cc12c8746ba44140ac8c976d5a23fecf",
      "7e3222dc777f44b18bf780290d6b9d1d",
      "8a1b60947d964cb18ceffefb5997bf44",
      "aa142709b85e4af28d9e6e419b8047c3",
      "0a19f9ec8f2746fb8805492fb8c2b285",
      "b384376666b8470486fa3afb89d2e099",
      "88689cf7a073423cb26025323811e642",
      "027144937cfe4cd3abaf4647b00c0fcf",
      "e38e12a9ed69438c9b773ad185765ca4",
      "4f0ece9b730e41329028b1c3337608cc",
      "c4f02ef823a54284a4079774300d7dbe",
      "1fadd47b94464b4fb5a099735683584d",
      "438b91bcadaa4857a07788ebea8a13df",
      "b71875355fbf46f8966a73c58265f572",
      "2aaacf29c21b4ccca8dafe9035d00fd2",
      "c556dd714c474cf6961b8822d1c7dbd9",
      "7b88a40da21b42e7bf4e74955ec9f6a1",
      "ed1a761d1e374aecbb82bcfef8a692b9",
      "f31c5195de314354a9e95638577fa778",
      "bfef98f27ebd477c983b18f0ff10dfeb",
      "33663a1580fe4a8385c1ba4fdc7e04de",
      "fc237f5c0c53450a8effc8b23408d46d",
      "45ac8e1df7a34eee9597b1df0f02fb24",
      "12dd1ec1a7454c598f4002342074e7d6",
      "43781e9c6b7b4d91b7f0e6568da1c041",
      "042fb908dfd64e6a80438ea57d18a2d7",
      "db39f7b79f1d4abeae8725368c4d9df9",
      "aed5f87365a649ce9d07241687cbc165",
      "24cb537309e94aa993aa5d6ca1dd5b03",
      "f691f289f27942c38447c4d04b3b2018",
      "0251b88692df44688b0ff26d7629bed0",
      "83dbd1c0361f43a888a4758027e99aab",
      "273b0054e0834e50988a8bde13161295",
      "799873ccb3a94dbeb9e9c604d03ecb35",
      "b0b47f4343344ddf99559b27fab6fd5a",
      "2dbc2c66e1604bd5bc424fe29a5a2325",
      "8aebd40abf70427791116f8a8e30851f",
      "e5dae727f27f4984bd141abc20084657",
      "52999766033741d9a81f4f9da7fd02d4",
      "eb9a5b0d5f7f45548005a1155cf3e237",
      "f107bf601845471881c311dba80a844b"
     ]
    },
    "executionInfo": {
     "elapsed": 18521,
     "status": "ok",
     "timestamp": 1635956219845,
     "user": {
      "displayName": "Sandip Panesar",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03744674344979941942"
     },
     "user_tz": 420
    },
    "id": "PMtRGiWBlxXU",
    "outputId": "9ff7b6fe-3df0-4449-9731-1977711cf2f7"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a17f97492e7d4840857fd45597fb5be6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "962625fe6a4e4c5ba2ddf870211eadb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e38e12a9ed69438c9b773ad185765ca4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfef98f27ebd477c983b18f0ff10dfeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0251b88692df44688b0ff26d7629bed0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/420M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Initialize tokenizer and model objects from HuggingFace transformers library\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "model = AutoModelForMaskedLM.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8A8I2Hn1nUSb"
   },
   "source": [
    "Lets use the above contextual examples of the word *flies* to see how the word representation produced by BERT changes depending upon context. \n",
    "\n",
    "Before being passed into BERT, the text needs to be tokenized using the BERT-model tokenizer first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1635956219845,
     "user": {
      "displayName": "Sandip Panesar",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03744674344979941942"
     },
     "user_tz": 420
    },
    "id": "jMAw6aFvmqAm"
   },
   "outputs": [],
   "source": [
    "ct_1 = tokenizer.tokenize(\"there are flies in my kitchen\")\n",
    "ct_2 = tokenizer.tokenize(\"jane flies to london on tuesday\")\n",
    "\n",
    "tk_1 = tokenizer.convert_tokens_to_ids(ct_1)\n",
    "tk_2 = tokenizer.convert_tokens_to_ids(ct_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "muFdu4K-oEXV"
   },
   "source": [
    "Which produces two sequences of unique tokens corresponding to BERT's unique vocabulary of ~30,000 words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1635956219846,
     "user": {
      "displayName": "Sandip Panesar",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03744674344979941942"
     },
     "user_tz": 420
    },
    "id": "nUTyEETlnpOj",
    "outputId": "1222d250-a9b6-4dee-9612-6281d54ba00d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context 1:\n",
      "['there', 'are', 'flies', 'in', 'my', 'kitchen']\n",
      "[2045, 2024, 10029, 1999, 2026, 3829]\n",
      "Context 2:\n",
      "['jane', 'flies', 'to', 'london', 'on', 'tuesday']\n",
      "[4869, 10029, 2000, 2414, 2006, 9857]\n"
     ]
    }
   ],
   "source": [
    "print(\"Context 1:\")\n",
    "print(ct_1)\n",
    "print(tk_1)\n",
    "print(\"Context 2:\")\n",
    "print(ct_2)\n",
    "print(tk_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tFAgpbDypK7k"
   },
   "source": [
    "In this particular case, we are interested in the word \"flies\", which is the 3rd word in the first example, and the 2nd word in the second example. Note that this number is the same for both (10029) and represents the index sequence for the particular word in the pre-trained BERT's context-agnostic word-representation matrix. NB: As BERT uses subword pooling, some words that don't appear in the BERT vocabulary may be constructed from multiple tokens. In this example, there are as many tokens as there are words in each sentence, however be aware that there may be more tokens in a particular tokenized sequence.\n",
    "\n",
    "The next step is to encode the tokenized sequences using the model's encoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 378,
     "status": "ok",
     "timestamp": 1635956220211,
     "user": {
      "displayName": "Sandip Panesar",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03744674344979941942"
     },
     "user_tz": 420
    },
    "id": "kQCLJ-oYoG8E"
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "  reps_1 = model(torch.tensor([tk_1]), output_hidden_states=True)\n",
    "  reps_2 = model(torch.tensor([tk_2]), output_hidden_states=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I2k0lf9Ire0Z"
   },
   "source": [
    "Above, we have passed the tokenized examples into the BERT model architecture, and have extracted the hidden states for each one. The output will be in the form of a \"masked LM output\", which can be indexed like a list object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1635956220212,
     "user": {
      "displayName": "Sandip Panesar",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03744674344979941942"
     },
     "user_tz": 420
    },
    "id": "gca7Zj_DrbhP",
    "outputId": "b4028f4b-4b70-446f-98e7-85acc3f4fb0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the 'reps_1' object: 13\n",
      "Length of the 'reps_2' object: 13\n"
     ]
    }
   ],
   "source": [
    "print(\"Length of the 'reps_1' object: {}\".format(len(reps_1[1])))\n",
    "print(\"Length of the 'reps_2' object: {}\".format(len(reps_2[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "84z2iB8es2xL"
   },
   "source": [
    "Why is the length of this object 13? Because there are 13 unique layers in the BERT model architecture (there are actually 12, but the input layer gets counted). Following the input, the context-agnostic representations (which are indexed using the unique tokens) get successively multiplied by the unique weight matrices of each layer to produce a final output.\n",
    "\n",
    "Lets look further into the the model outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1635956220212,
     "user": {
      "displayName": "Sandip Panesar",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03744674344979941942"
     },
     "user_tz": 420
    },
    "id": "wA1PaXj4r5zo",
    "outputId": "f527aa26-0dd1-42f2-e6ec-9ca0f8e30e7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of first item in 'reps_1' object: <class 'torch.Tensor'>\n",
      "Shape of first item in 'reps_1' object: torch.Size([1, 6, 768])\n"
     ]
    }
   ],
   "source": [
    "print(\"Type of first item in 'reps_1' object: {}\".format(type(reps_1[1][1])))\n",
    "print(\"Shape of first item in 'reps_1' object: {}\".format(reps_1[1][1].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EsJmLQsRuHWG"
   },
   "source": [
    "Here we can see that the output of the model is a Torch tensor object. Its shape is 1 x 6 x 768. Remember this is a tensor, rather than a simple matrix. We can ignore the 1st dimension for the time being. The second dimension is 6, because there were 6 words in the particular sentence for the first example (\"there are flies in my kitchen\"). Why is the 3rd dimension 768? Because the BERT model uses this dimensionality as a default for all word representations. Therefore, the model output has been a sequence of 13 torch tensors of size 1, 6, 768, which are the unique BERT output representations produced by all 13 layers of the model. We would expect the same dimensionalities for the second example (\"Jane flies to London on Tuesday\") also. \n",
    "\n",
    "Looking further into the outputs from the 1st BERT layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1635956220213,
     "user": {
      "displayName": "Sandip Panesar",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03744674344979941942"
     },
     "user_tz": 420
    },
    "id": "dvo_reomuADV",
    "outputId": "5306bc4d-c6b5-4caf-ba51-f4ba65aaeab1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.3371,  0.0284, -0.0151,  ...,  0.1688,  0.5847,  0.2671],\n",
       "         [ 0.1085, -0.5766,  0.5589,  ...,  0.8240,  0.8500,  0.2674],\n",
       "         [ 1.2492,  0.4529,  0.3716,  ...,  0.4312,  1.6800, -0.7760],\n",
       "         [-0.3168, -0.4342,  0.3652,  ...,  0.8458, -0.1063,  0.4743],\n",
       "         [ 0.0768,  0.0895, -0.5986,  ..., -0.1931,  0.1779, -0.1596],\n",
       "         [ 1.1235,  1.1240, -1.7649,  ...,  0.0018,  0.5081, -1.2387]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reps_1[1][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4SQmQMWPxqOj"
   },
   "source": [
    "Above is the particular sequence of unique BERT representations for each word in the sentence for example 1. We know that the word of interest, \"flies\" is the 3rd word in the sequence and is represented by a single, rather than multiple subword tokens. We can extract this from the sequence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1635956220213,
     "user": {
      "displayName": "Sandip Panesar",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03744674344979941942"
     },
     "user_tz": 420
    },
    "id": "X5lGxteyxnm5",
    "outputId": "3c37e914-de1e-407c-ea29-74fe23793e01"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.2492,  0.4529,  0.3716, -0.2537, -0.6448, -0.5668,  0.2715,  0.0713,\n",
       "         0.5645,  0.2954,  0.1321, -0.2661, -1.3168, -0.8103,  0.7747, -0.1451,\n",
       "        -0.3072, -0.8303,  0.0562,  0.0047,  0.9308, -1.1341, -0.0853, -0.6373,\n",
       "         1.1573, -0.7362,  0.3110,  0.6170, -0.3286,  0.1840, -1.2341, -0.5636,\n",
       "         0.1067,  0.0057,  0.3447, -0.1934, -0.8136, -0.7385, -0.3345, -0.0770,\n",
       "         0.8960, -1.0697, -0.6062, -0.7009, -0.0875,  0.0882, -1.0935,  1.3017,\n",
       "         0.9258, -0.0748, -1.0685,  0.7274,  0.4908,  0.4242, -0.2799, -0.6097,\n",
       "         1.0959,  0.5043, -0.2942, -0.3891, -0.9965, -0.6558, -0.1532,  1.0867,\n",
       "        -1.0657,  0.1961, -0.9462,  0.4023, -1.3862, -0.0482,  1.5956,  0.3197,\n",
       "        -0.0546, -1.3346,  0.1428,  0.3159,  0.5501,  0.6684,  1.0249, -0.0060,\n",
       "        -0.8474, -1.3680,  0.7003,  0.2155, -0.4345, -0.2939, -0.3236, -0.1450,\n",
       "        -0.5835, -0.2909,  0.0689, -0.1768,  0.2719,  0.2286,  0.1724,  0.3491,\n",
       "         0.0193,  0.0952, -0.7759, -1.5101, -0.8622,  0.7132,  0.4775, -0.2401,\n",
       "         0.8135,  0.4957, -0.1845, -0.7730,  0.0051,  0.5918, -0.1521,  0.5973,\n",
       "        -0.2387,  0.8913,  0.3966,  0.4433,  0.5864, -0.0299,  1.1895, -0.5537,\n",
       "        -0.2821, -0.2566, -0.2321, -0.7347, -0.7301,  0.2598,  0.4928, -0.3527,\n",
       "        -1.0351, -0.7879,  0.1275,  0.0207,  0.4765, -0.8732,  0.5629, -0.3684,\n",
       "        -1.3534,  0.0557, -0.0261, -0.8970,  1.3888, -0.2945, -1.2076, -0.2438,\n",
       "        -0.1915, -0.2736,  0.0117,  0.6536, -0.1838, -0.2317,  0.7437, -0.1308,\n",
       "        -0.3347, -0.1356, -1.1960, -0.7435,  0.8873,  0.6684,  0.9499,  0.5218,\n",
       "         0.2318,  0.4782,  0.4923, -0.3577,  1.6855,  0.0288,  0.2429, -0.3146,\n",
       "        -0.9066, -0.2101,  0.9528,  0.3391,  0.7731,  0.7297,  0.6739,  0.0672,\n",
       "        -0.3950,  0.1761, -0.8200, -0.7337,  1.1471,  0.7128, -0.1411,  0.5254,\n",
       "         0.0201,  0.0178, -0.3041, -0.4632, -0.2956,  1.0564, -0.9977, -0.3981,\n",
       "         0.6890, -0.1231,  0.7876,  0.9794,  1.4824, -0.2431,  0.5696, -0.4744,\n",
       "         0.5394,  0.0384,  0.4859,  0.3510, -1.3418, -0.3960, -0.0360,  0.3528,\n",
       "        -0.3925,  0.1583, -0.1715, -0.4692,  1.4265,  0.2900,  0.1309,  0.0157,\n",
       "        -0.2951, -0.9023,  0.5777, -0.0180, -0.3998,  0.1425,  0.3527,  0.8664,\n",
       "        -0.1214,  0.2194,  1.0814,  0.6659, -0.2814, -0.1629, -0.0411, -0.9338,\n",
       "        -0.8602, -0.2394, -0.8002,  0.5456,  0.5766,  0.2944,  0.2024, -0.7249,\n",
       "        -1.0123,  0.7500, -0.1734,  0.4782, -0.8449, -0.2750,  0.2900,  0.0331,\n",
       "         0.5172, -0.9114,  0.0699,  0.7965,  1.2175, -0.5487, -0.2669, -0.0266,\n",
       "         0.2084, -0.2711,  0.3684, -0.4347, -0.8361,  0.2819,  1.2863, -0.3365,\n",
       "         0.2562,  1.0599, -0.8628,  0.5573,  0.9950, -0.6027,  0.2245, -1.4064,\n",
       "        -0.2263, -0.4502, -1.6841, -0.2925,  0.5035,  0.0191, -0.7955, -0.8608,\n",
       "        -0.3359,  0.5472,  0.5521, -0.7859,  0.8854,  0.4790, -0.4877, -0.3193,\n",
       "         0.4936,  0.2308, -0.2102,  0.7791, -0.5487,  0.0422,  1.0313,  0.3383,\n",
       "         0.1055, -1.2658, -1.0542, -0.4575,  1.2557,  0.2779,  0.6992, -0.4931,\n",
       "         0.7439,  0.9415,  0.4984,  0.0206, -1.5225, -0.3415, -0.1172,  1.1988,\n",
       "         0.1627, -0.5996,  0.8728,  0.8920,  0.3760, -0.6926, -0.2809,  0.4535,\n",
       "        -0.0740, -0.2595, -0.0487,  1.3460,  0.1124, -1.5100, -0.4386, -0.0778,\n",
       "         0.2957, -0.4322, -0.0717, -0.3892,  0.5897, -0.3352,  0.2302,  0.4294,\n",
       "        -0.5469, -0.1761, -0.1688,  0.5742, -0.2189, -0.0526,  0.5029, -0.0568,\n",
       "         0.0968,  1.0488,  0.4573, -0.4667, -0.3290, -1.1292, -0.6442,  0.6775,\n",
       "        -0.7405, -0.8931, -1.1445, -0.5328, -0.4252,  0.7591, -0.1211, -0.8275,\n",
       "        -0.6515, -0.2841,  0.4232, -1.2136,  1.0530,  0.2568, -0.6339, -0.3776,\n",
       "        -0.2642, -0.7700, -0.1794, -0.7006, -0.6352,  1.0020,  0.0569,  1.2361,\n",
       "        -0.7463, -0.6786,  0.1609,  1.2862,  0.9716, -0.4413, -0.6756,  0.1439,\n",
       "        -0.1990,  0.7656,  0.0385,  1.0182, -0.2838,  0.0945, -0.2948, -1.1044,\n",
       "        -0.2878, -0.1109, -1.9291,  0.2153, -0.2895, -0.8982, -0.2240,  0.0935,\n",
       "         1.3625, -0.6952,  0.0175, -0.6281, -0.8295, -0.4395, -0.7595, -0.0710,\n",
       "         0.1984, -0.9486,  1.3262,  0.2405,  1.0137, -2.8433, -0.1000,  0.3178,\n",
       "         0.3147,  0.2575,  1.2800,  0.1189,  0.4984, -0.5153, -0.5908, -0.2318,\n",
       "        -1.3656, -0.5253,  0.6050, -0.3368,  1.3780, -1.6641,  1.2890,  0.1797,\n",
       "        -0.1959,  0.3728, -0.3150,  0.8337,  0.7736,  0.0599, -0.0163,  0.7157,\n",
       "        -0.0779, -0.5508,  0.0871, -0.0809, -0.0218,  0.0845, -0.3180, -0.8480,\n",
       "        -0.0038,  0.5963,  1.0264,  0.1764,  0.1306,  0.3050,  0.0355,  0.1567,\n",
       "         0.2174,  0.0941, -0.8850, -1.0664, -1.0925,  1.8376, -0.5640,  0.4161,\n",
       "        -0.8344,  1.4551,  0.6757, -1.1571,  0.1496,  0.3692,  0.2063,  0.5154,\n",
       "        -0.8923,  1.2191,  1.3545, -0.0210,  0.2101, -0.6285,  0.4745,  0.3262,\n",
       "        -0.5980, -1.2036,  0.1159,  0.3567, -1.4235,  0.1993, -0.4399,  0.9858,\n",
       "        -0.1095,  0.0672, -1.0222, -0.6416,  0.3424,  1.4399, -0.2496, -0.8594,\n",
       "        -0.4941, -0.1922, -0.8419, -0.3246, -0.9298,  0.2192,  0.8258, -1.2030,\n",
       "        -0.1301, -1.3974,  0.0098, -0.6431, -0.5031,  0.4927,  1.0029,  0.0363,\n",
       "         0.5127,  0.2150, -0.6076,  0.1411, -1.1456,  0.4100, -1.3571, -0.4583,\n",
       "         1.0876, -0.2048, -1.4045,  0.6901,  0.3415,  0.1539, -0.4782,  0.9277,\n",
       "         0.9456, -0.4287,  0.5497, -1.9387,  1.1021,  0.3516, -0.3663, -0.7833,\n",
       "        -0.1578, -0.7567, -0.5469, -0.1552, -0.8059, -0.9715, -0.0617,  1.1118,\n",
       "        -1.2968,  0.1477, -1.2966, -0.2435, -0.9924,  0.7396, -2.5401, -0.0093,\n",
       "        -0.2474, -0.5228, -1.2188, -0.9115,  0.4424, -0.7439, -0.4768, -0.0206,\n",
       "         0.7003, -0.2947, -0.2204,  0.7943,  0.0176,  1.2946, -0.0129, -1.0707,\n",
       "        -0.7876,  1.0388,  0.8011, -0.5344, -0.5786, -0.3715,  0.8647,  0.3357,\n",
       "         0.0491, -0.0476, -0.3047,  0.7231,  0.8877,  0.6077,  1.0517,  0.0785,\n",
       "        -0.5241,  0.9934,  0.2349, -0.1243,  0.3134, -0.8433, -0.3450,  0.0619,\n",
       "        -1.1358, -0.3269,  0.4567,  1.2497,  0.3531,  1.0701,  0.3840,  1.2706,\n",
       "         0.2765, -0.9637, -1.0881, -0.1787, -0.9362, -0.1605,  0.6947, -0.0855,\n",
       "        -0.2743, -0.5407, -0.7556, -0.1324, -0.7857,  0.2263, -0.1262,  0.1656,\n",
       "         1.1879, -0.2089,  0.2343,  0.6430, -0.7571,  0.1058, -0.4416, -0.1387,\n",
       "        -0.6562,  0.1876, -0.7625, -0.6552,  0.3919, -0.6951,  0.5330,  0.1668,\n",
       "        -1.3850, -0.4782,  1.0680,  0.2928, -0.8918, -1.1266, -0.2208, -0.2818,\n",
       "        -1.2160, -0.6193,  1.0577,  0.1844,  0.8720, -0.0400,  0.1744, -0.1352,\n",
       "         0.3153,  1.0847, -0.2883,  1.2217,  0.2136,  0.2880, -0.6447,  0.4502,\n",
       "         1.7451, -0.3931, -1.0506, -0.3283,  0.8240, -1.7316,  0.8760,  0.0639,\n",
       "         1.2137,  0.1963,  0.6648,  0.2380,  0.3661,  1.0746,  0.0639, -0.7984,\n",
       "         0.0254,  0.2959,  1.1680, -0.0395,  0.9916, -0.0033, -0.3245, -2.0264,\n",
       "         0.1374,  0.5130,  1.0157,  0.9436, -0.4648,  0.2483,  0.8906, -0.5310,\n",
       "         0.1180, -0.9866,  0.8141,  1.7413,  0.1887, -0.0904,  0.2429, -0.2663,\n",
       "         0.9085, -0.1037, -0.6517,  0.4468, -0.1773, -0.5435, -0.1423,  0.4687,\n",
       "        -0.0739,  1.0426,  0.0962,  0.5875,  0.1411, -0.8676, -0.9021, -1.1596,\n",
       "        -0.9560, -1.2234, -0.3415, -0.5678,  0.8475,  0.8331,  1.0098, -0.1704,\n",
       "         0.0315,  0.2442,  0.9974, -0.2090, -0.3976, -0.4620, -0.0167, -0.0177,\n",
       "        -1.2916,  0.3848, -0.8662,  0.6306,  0.9643, -1.4354,  0.3319,  0.2481,\n",
       "         0.6070, -0.3436, -0.7972,  0.6062, -0.1040, -0.6052, -1.6598, -0.1583,\n",
       "         0.7030,  0.6026,  0.8618,  0.4415,  0.0131, -0.0921,  0.6713, -1.3061,\n",
       "         0.5559, -0.5294, -0.1885, -0.2608, -0.3658, -0.4358, -1.3866,  0.0929,\n",
       "        -0.7398, -0.2022, -1.0485,  1.5658,  0.4288,  0.4312,  1.6800, -0.7760])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reps_1[1][1][0][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YGP5uqBnyPZy"
   },
   "source": [
    "This is the unique representation sequence vector for the word \"flies\" in this instance. \n",
    "\n",
    "To exemplify the difference between the word \"flies\" produced from this context and the word produced in the second exemplary context, lets compare whether they are the same:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1635956220214,
     "user": {
      "displayName": "Sandip Panesar",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03744674344979941942"
     },
     "user_tz": 420
    },
    "id": "I0AyUmghyCVp",
    "outputId": "4be25d4e-5659-47bb-f557-e3b6cebbc4db"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.equal(reps_1[1][1][0][2], reps_2[1][1][0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LPZr2Lfey3K9"
   },
   "source": [
    "Thus, we have demonstrated that the BERT word representation for \"flies\" is different due to each context. This would be the same for all other layers, e.g. the 12th layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1635956220214,
     "user": {
      "displayName": "Sandip Panesar",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03744674344979941942"
     },
     "user_tz": 420
    },
    "id": "65QYVHqXyl7m",
    "outputId": "90c49eaf-c87e-43d7-bfbd-fc59e6cd95e5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.equal(reps_1[1][12][0][2], reps_2[1][12][0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u1heGobrzcA9"
   },
   "source": [
    "**Converting Contextual Word Representations into Static Word Representations**\n",
    "\n",
    "Above, we showed how BERT produces unique, contextualized representations for a single word depending upon a context in which it appears. Nevertheless, these representations, aside from being different in dimensionality from those produced by a Word2Vec or GloVe model, cannot readily be compared to vectors produced by the latter language models. This is because word representations produced by Word2Vec, for example, are representative of the word as it appears in in all contexts in a particular corpus, whereas these representations are representative of the words in that particular example only. Thus, in an attempt to permit comparability for academic and other reasons, Bommasani et al. (2020) devised a method to convert contextual word representations (like the ones we have just produced) into those that are similar to those produced by static language models. \n",
    "\n",
    "Specifically, Bommasani et al. (2020) proposed two methods to produce word representations from contextual language models that were comparable to those produced by static models. The first is simply to use a single context for each word, like we have done above. Nevertheless, even though in theory BERT has been trained on corpora much larger than would be practical to train a Word2Vec or GloVe model on, it can be shown that at various language benchmarking tasks such as SimLex999 and SimVerb3500 (see Bommasani paper for more detail), using a single contextualized example substantially underperforms compared to static language models.\n",
    "\n",
    "Another potential approach is to aggregate several contextual examples and produce a single, aggregated word representation for each word. Though this is a largely experimental technique, Bommasani et al. (2020) demonstrated that using this approach, word representations substantially outperformed those produced by static language models at various language benchmarking tasks. The following sections will demonstrate various approaches to achieve this. The utils.py file contains some helper functions.\n",
    "\n",
    "**Batch Encoding a Series of Sentences**\n",
    "\n",
    "If we want to aggregate a series of contextual examples for a particular word of interest, we will need to encode all of these. Lets use the word \"interest\" in this example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1635956220214,
     "user": {
      "displayName": "Sandip Panesar",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03744674344979941942"
     },
     "user_tz": 420
    },
    "id": "Iw5kT3gllPwY"
   },
   "outputs": [],
   "source": [
    "# Lets define some helper functions first:\n",
    "\n",
    "def encode(text, tokenizer, add_special_tokens=False):\n",
    "    encoding = tokenizer.encode(\n",
    "        text,\n",
    "        add_special_tokens=add_special_tokens,\n",
    "        return_tensors='pt')\n",
    "    if encoding.shape[1] == 0:\n",
    "        text = tokenizer.unk_token\n",
    "        encoding = torch.tensor([[tokenizer.vocab[text]]])\n",
    "    return encoding\n",
    "\n",
    "def represent(batch_ids, model, layer=-1):\n",
    "    with torch.no_grad():\n",
    "        reps = model(batch_ids, output_hidden_states=True)\n",
    "        return reps.hidden_states[layer]\n",
    "\n",
    "def find_sublist_indices(sublist, mainlist):\n",
    "    indices = []\n",
    "    length = len(sublist)\n",
    "    for i in range(0, len(mainlist)-length+1):\n",
    "        if mainlist[i] == sublist:\n",
    "            indices.append(i)\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1635956220215,
     "user": {
      "displayName": "Sandip Panesar",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03744674344979941942"
     },
     "user_tz": 420
    },
    "id": "JODhePplIVev"
   },
   "outputs": [],
   "source": [
    "batch = ['the bank account accrued interest over time', \n",
    "         'do you have any interest in this job opportunity?', \n",
    "         'Jane did not show any interest in Tom', \n",
    "         'the central bank adjusted the interest rates']\n",
    "\n",
    "encoded_batch = [encode(example, tokenizer) for example in batch]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NUDEVn4wexL3"
   },
   "source": [
    "This produces a list of token sequences for each of the examples in the batch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1635956220215,
     "user": {
      "displayName": "Sandip Panesar",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03744674344979941942"
     },
     "user_tz": 420
    },
    "id": "j5Si8VlBeMGj",
    "outputId": "496fdf83-bcd6-4b1a-a8bf-dcf838816134"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 1996,  2924,  4070, 16222, 28551,  3037,  2058,  2051]]),\n",
       " tensor([[2079, 2017, 2031, 2151, 3037, 1999, 2023, 3105, 4495, 1029]]),\n",
       " tensor([[4869, 2106, 2025, 2265, 2151, 3037, 1999, 3419]]),\n",
       " tensor([[ 1996,  2430,  2924, 10426,  1996,  3037,  6165]])]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uGjdesZPfPhU"
   },
   "source": [
    "The next step would be to then pass each of these example sequences into the model and obtain the model representations for each. For this example we are using layer 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 534,
     "status": "ok",
     "timestamp": 1635956220741,
     "user": {
      "displayName": "Sandip Panesar",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03744674344979941942"
     },
     "user_tz": 420
    },
    "id": "qIP2PA4nfOqg",
    "outputId": "81a08c65-026d-496a-bfba-c020503f61fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of 'batch_reps': 4\n",
      "Shape of BERT output for example 1: torch.Size([1, 8, 768])\n",
      "Shape of BERT output for example 2: torch.Size([1, 10, 768])\n",
      "Shape of BERT output for example 3: torch.Size([1, 8, 768])\n",
      "Shape of BERT output for example 4: torch.Size([1, 7, 768])\n"
     ]
    }
   ],
   "source": [
    "batch_reps = [represent(example, model, layer=1) for example in encoded_batch]\n",
    "\n",
    "batch_reps\n",
    "\n",
    "print(\"Length of 'batch_reps': {}\".format(len(batch_reps)))\n",
    "\n",
    "for idx, item in enumerate(batch_reps):\n",
    "  print(\"Shape of BERT output for example {}: {}\".format(idx+1, item.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yEtrzSl7-WT0"
   },
   "source": [
    "Here, we have encoded each of the 4 examples using the tokenized sequences. We can see that the representation lengths correspond to the lengths of the examples from the 'encoded_batch' list, and each of these items corresponds to a 768-dimensional vector for each token representation. \n",
    "\n",
    "Nevertheless, these representations are for **all** words in the example sequences. In order to aggregate contextual representations, we need to extract the representations corresponding to only the word of interest, i.e. the word of interest in this example is \"interest\". We achieve this using an indexing function that is able to extract the representation (or representations, in the case of multiple subwords) from the sequences we have produced.\n",
    "\n",
    "We utilize a special function for this, which is able to index and pull out the representations for the word of interest using the sequence of tokens and the sequence of reps, but first we need to get this token from the BERT model tokenizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1635956220741,
     "user": {
      "displayName": "Sandip Panesar",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03744674344979941942"
     },
     "user_tz": 420
    },
    "id": "ancVpOWde4MJ",
    "outputId": "a487e4f0-34d4-4b97-aaad-04a9fe757bd4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3037]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toi = encode('interest', tokenizer)\n",
    "\n",
    "toi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dHQ_fNPTBnuc"
   },
   "source": [
    "In our case, 3037 is the token of interest, thus we need to pull the representation from the representation sequence that corresponds to the index for 3037 in the sequence of tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1635956220741,
     "user": {
      "displayName": "Sandip Panesar",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03744674344979941942"
     },
     "user_tz": 420
    },
    "id": "VEp-hIiGBcbi",
    "outputId": "66973e33-5718-4a5d-fe7c-fe5a883c906c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[5], [4], [5], [5]]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = [find_sublist_indices(toi, id.squeeze(0)) for id in encoded_batch]\n",
    "    \n",
    "indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CM2DSourDyHt"
   },
   "source": [
    "Above are the corresponding index positions for the word \"interest\" in each contextual example. The next step would be to extract the corresponding representations from the representation sequences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1635956220742,
     "user": {
      "displayName": "Sandip Panesar",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03744674344979941942"
     },
     "user_tz": 420
    },
    "id": "5BCiTu-iCKzZ",
    "outputId": "1a7dd1ed-5325-4290-bde9-f25e4d1dd436"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of 'final_reps': 4\n",
      "Shape of object 1 in 'final_reps': torch.Size([1, 768])\n",
      "Shape of object 2 in 'final_reps': torch.Size([1, 768])\n",
      "Shape of object 3 in 'final_reps': torch.Size([1, 768])\n",
      "Shape of object 4 in 'final_reps': torch.Size([1, 768])\n"
     ]
    }
   ],
   "source": [
    "final_reps = [rep.squeeze()[idx] for idx, rep in zip(indices, batch_reps)]\n",
    "\n",
    "print(\"Length of 'final_reps': {}\".format(len(final_reps)))\n",
    "\n",
    "for idx, item in enumerate(final_reps):\n",
    "  print(\"Shape of object {} in 'final_reps': {}\".format(idx+1, item.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SMrpwNBQFjWT"
   },
   "source": [
    "Above, we can see that there are 4 items in this list, corresponding to all 4 examples. We can also see that each of these is a 1 x 768 dimensional tensor. These are the individual, unique contextualized representations for the word \"interest\" which was influenced by the unique sequence of words that appeared around this word in each contextual example.\n",
    "\n",
    "Now, all that is left to do is take the mean for the example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1635956220742,
     "user": {
      "displayName": "Sandip Panesar",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03744674344979941942"
     },
     "user_tz": 420
    },
    "id": "zNXlXyS3Eo_O",
    "outputId": "6bf4cbeb-2d76-4fbd-e07a-ae6ac22c3ae7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the final, aggregated vector is: torch.Size([768])\n",
      "tensor([-1.5860e-01,  4.2653e-01, -1.3746e+00, -2.0712e-01,  1.4237e+00,\n",
      "         3.5543e-01, -4.3161e-01,  1.3834e-01, -6.5748e-01, -9.0278e-01,\n",
      "         8.9920e-01, -8.3442e-01, -1.6335e+00,  5.8129e-01, -8.0425e-01,\n",
      "         2.4763e-02,  4.5348e-01, -1.6919e-01,  5.5616e-01, -6.3543e-01,\n",
      "         1.3068e+00, -4.7555e-01,  5.5960e-01, -6.5125e-01,  1.9772e-01,\n",
      "         4.9402e-02, -1.1139e+00,  8.9068e-01, -6.4682e-01,  1.4834e-01,\n",
      "        -1.3721e-01, -5.6790e-01,  2.8271e-01,  8.3907e-01, -2.5547e-01,\n",
      "        -2.4574e-01,  4.2206e-01, -4.1671e-01, -2.5220e-01,  7.0160e-01,\n",
      "         1.2924e-01,  1.0697e-01, -7.5490e-01, -4.6156e-01, -5.2881e-01,\n",
      "        -9.4269e-01, -1.2130e-01,  4.7840e-01, -7.9150e-02, -1.2404e+00,\n",
      "        -3.1382e-01,  1.7650e-01,  8.0450e-02,  8.2559e-01,  7.4104e-01,\n",
      "         7.0324e-01,  5.3583e-01,  7.3397e-01,  2.2428e-01, -9.2912e-01,\n",
      "         9.8462e-01, -4.0586e-01, -4.7924e-01, -7.9504e-01, -6.3908e-02,\n",
      "        -5.3131e-01,  3.1097e-02,  3.0646e-01, -3.0587e-01, -1.0773e+00,\n",
      "        -5.4721e-01,  1.6288e+00, -1.8654e+00, -3.2191e-01, -2.2648e-01,\n",
      "         2.7789e-01,  9.5068e-01, -3.0532e-03,  6.5227e-01, -5.1896e-01,\n",
      "        -6.0315e-01,  7.1159e-01,  6.1934e-01,  1.0446e+00,  9.3759e-01,\n",
      "        -9.6780e-01,  8.0934e-01, -4.3921e-01,  3.3956e-01,  6.0730e-01,\n",
      "         4.1845e-02,  1.0542e+00,  1.6489e-01, -3.9172e-01, -7.2639e-02,\n",
      "        -2.3748e-01,  7.4225e-03, -5.5275e-01, -9.9106e-02, -1.3811e+00,\n",
      "         6.1617e-01, -5.1497e-01,  1.5946e-02, -7.0239e-01, -5.7934e-01,\n",
      "         2.7568e-01,  7.4934e-01, -5.2123e-01,  5.2126e-01, -1.8984e-03,\n",
      "         1.6791e-01,  1.1004e+00,  8.7902e-01,  8.0214e-03, -5.0986e-01,\n",
      "        -1.1008e+00, -2.3446e-01, -8.2213e-01,  1.4484e-01,  1.2547e+00,\n",
      "         8.5738e-02, -7.1032e-02,  5.2129e-01,  5.6957e-01, -5.7862e-01,\n",
      "         7.1118e-02,  1.7095e-03,  4.6204e-01,  6.9373e-01, -8.3163e-01,\n",
      "         1.1168e+00,  1.2350e+00,  2.6145e-02,  3.3437e-01,  7.1972e-01,\n",
      "        -5.0368e-01, -3.3186e-01,  1.3686e-01, -2.5096e-01,  4.5569e-02,\n",
      "         1.0784e-01, -1.2083e-01, -1.8829e+00,  8.7326e-01,  6.0515e-01,\n",
      "         2.3913e-01, -3.9376e-01,  4.6672e-01, -2.6113e-02,  1.7687e-01,\n",
      "        -1.4584e+00, -3.1044e-01,  5.4942e-01,  3.4144e-01, -1.6477e-02,\n",
      "        -8.7699e-01,  2.3980e-01, -9.2342e-01, -1.6086e+00,  6.4821e-01,\n",
      "         2.4183e-01,  1.8543e+00,  3.9370e-01,  1.2547e+00,  6.5685e-02,\n",
      "        -5.0811e-01,  1.4563e-01,  7.7402e-01, -1.5447e+00, -8.8696e-02,\n",
      "        -2.4739e-01, -5.3354e-01,  7.3980e-01,  8.8337e-01,  7.8465e-01,\n",
      "         9.4442e-02,  2.3890e-01, -5.3917e-01, -1.6414e-01, -1.0229e-01,\n",
      "         1.3037e+00, -1.5132e+00, -8.5188e-01, -5.5334e-02,  1.2268e+00,\n",
      "        -6.0790e-01, -1.5811e-01,  1.3478e-01, -5.5609e-02, -4.6245e-01,\n",
      "        -4.3588e-01,  6.3366e-02, -5.4084e-01, -7.6265e-01,  1.2105e+00,\n",
      "        -2.8602e-01, -8.1360e-01, -7.0994e-01,  2.5168e-02, -6.1900e-01,\n",
      "         8.5171e-01, -1.1777e-01,  6.3138e-01, -5.2758e-01, -7.8671e-01,\n",
      "        -1.0676e-01,  1.4167e+00, -1.9822e-02,  5.4414e-01, -6.1803e-01,\n",
      "        -5.3916e-01,  1.1479e+00,  5.5508e-02, -6.4132e-01,  2.1315e-01,\n",
      "         3.2082e-01,  5.6710e-02,  7.0118e-01,  4.9288e-01, -9.9210e-02,\n",
      "        -6.3711e-01, -5.1909e-01, -1.2446e-01, -2.3238e-01,  6.7540e-01,\n",
      "        -5.3180e-01, -1.4608e-01, -3.1019e-01,  4.0958e-01,  5.7259e-01,\n",
      "         1.9139e-01, -5.7841e-01,  8.2055e-01,  1.0162e-01,  4.0523e-01,\n",
      "         2.2258e-01, -5.3521e-01, -4.4764e-01,  6.2921e-01,  3.7334e-01,\n",
      "        -9.2207e-01,  7.6321e-01, -1.2291e+00,  8.6247e-01, -1.0194e+00,\n",
      "         1.9398e-01, -2.6082e-01, -7.9227e-01,  4.2555e-01, -8.2643e-02,\n",
      "        -7.5286e-02,  1.3927e-01, -6.3335e-01,  9.5022e-01,  1.6103e-01,\n",
      "        -7.0588e-02, -6.9644e-02, -6.1694e-01,  7.3180e-01,  5.2783e-02,\n",
      "         9.0381e-01,  5.4578e-01, -4.2317e-01,  2.8502e-01, -1.0793e+00,\n",
      "        -8.4161e-01,  1.8135e-01, -5.9093e-01,  4.9789e-01, -1.6748e+00,\n",
      "         3.7100e-01,  1.3050e-01, -2.6899e-01,  7.2215e-01,  6.7271e-01,\n",
      "        -1.8358e+00,  1.0007e+00, -5.1861e-01,  2.2257e-01, -1.0714e+00,\n",
      "        -3.7143e-01, -1.1305e+00, -3.7646e-01, -4.9616e-01,  3.0750e-01,\n",
      "         5.7212e-01,  4.9519e-01, -9.5993e-02, -5.9622e-02,  7.8066e-01,\n",
      "        -7.6769e-01,  1.9289e-01, -1.3197e+00,  5.3703e-01,  1.4637e+00,\n",
      "         2.6120e-02, -1.1087e-01,  4.3130e-01, -9.8719e-01, -9.1922e-01,\n",
      "         3.1023e-01,  2.6201e-01, -3.7267e-01, -1.2909e-01,  3.4624e-01,\n",
      "        -1.0456e+00, -8.6829e-01,  5.9481e-02, -2.2732e+00, -2.6375e-02,\n",
      "        -1.0215e+00,  7.1120e-01, -3.8735e-01,  6.0564e-01, -7.8726e-01,\n",
      "        -3.1165e-01, -4.6143e-01, -1.8373e-02, -1.1797e+00,  6.8444e-01,\n",
      "         7.8286e-01,  4.4840e-01,  1.0236e+00,  3.6420e-01,  2.7796e-01,\n",
      "         4.4944e-01, -1.2771e-01, -8.2881e-01,  5.8659e-02, -3.9495e-02,\n",
      "         7.6358e-02, -7.3230e-01, -2.3032e-01,  2.7533e-01, -2.2188e-01,\n",
      "        -5.7923e-01,  3.9429e-01,  7.6034e-01, -5.2405e-01,  4.8414e-01,\n",
      "        -9.6347e-01,  1.0741e+00, -1.1213e-01, -2.5750e-01,  9.3734e-03,\n",
      "         8.0224e-01, -7.0565e-01,  1.3715e-01, -4.0046e-01, -7.2520e-01,\n",
      "        -5.0418e-01, -6.6935e-01, -9.3029e-01, -3.0767e-02, -9.7216e-01,\n",
      "        -2.8068e-01,  3.1863e-02, -2.3329e-01, -2.9532e-01,  5.5928e-01,\n",
      "        -1.5881e-02,  7.0381e-01, -2.6354e-01, -3.0661e-01,  7.2397e-01,\n",
      "         4.4312e-01,  8.1623e-01,  1.1285e+00,  8.5065e-02, -1.5002e-01,\n",
      "         3.0461e-01,  2.6105e-01,  2.4116e-01, -4.5236e-01, -1.4200e+00,\n",
      "         5.0861e-01, -1.1044e-01, -3.9829e-01, -3.8577e-01,  1.1439e-01,\n",
      "        -1.0192e+00,  5.4644e-02, -9.6525e-01, -8.3965e-01,  1.1680e+00,\n",
      "        -1.7146e-01, -7.3841e-01,  3.6553e-01,  2.0538e-01,  5.8131e-01,\n",
      "        -4.7137e-01,  5.2564e-01, -1.2864e-01,  5.5730e-01, -6.5686e-01,\n",
      "        -7.7200e-01, -9.6278e-01, -6.7418e-01, -1.8133e-01, -4.1829e-01,\n",
      "         2.0767e-02,  9.1836e-01,  3.8684e-01, -5.5968e-01, -3.5752e-01,\n",
      "         6.0378e-01, -1.2716e+00, -5.1625e-01,  4.6730e-01, -4.1096e-02,\n",
      "        -1.2678e+00, -5.2542e-01,  1.3523e+00,  6.3109e-01,  1.0883e+00,\n",
      "        -3.7939e-01,  8.3418e-01, -2.2211e-02, -9.8847e-01,  8.9095e-02,\n",
      "         6.0969e-01, -5.5345e-01, -9.3717e-02, -1.2587e+00,  7.2381e-01,\n",
      "        -9.5254e-01, -1.5718e-01,  8.2207e-02, -2.1703e-01,  4.6317e-01,\n",
      "         1.2448e+00,  5.0929e-01,  6.9738e-02,  2.9512e-01,  7.5829e-01,\n",
      "         5.0683e-01, -1.0882e+00,  1.4532e-01,  9.2495e-01,  6.9610e-01,\n",
      "        -1.9789e-01,  2.2896e-01,  5.2008e-01, -1.3531e+00, -2.9437e-01,\n",
      "         5.0965e-01,  6.9636e-01,  7.4703e-01, -3.4615e-01,  9.5506e-01,\n",
      "        -7.7310e-01,  3.4275e-01,  7.4347e-01, -4.7044e-01,  1.6994e+00,\n",
      "        -8.9816e-01, -3.9577e-01,  2.7308e-01, -5.8560e-02, -1.1410e+00,\n",
      "        -5.7687e-01,  7.1397e-01,  3.0034e-01,  7.3499e-01, -1.6787e+00,\n",
      "         3.4892e-02,  2.2844e-01,  8.4259e-01, -5.5386e-01,  6.1118e-01,\n",
      "         3.3798e-01,  8.7676e-01, -8.6113e-01, -7.1552e-01,  6.2363e-01,\n",
      "        -1.5656e+00,  1.8327e+00,  2.5438e-01, -7.9853e-02, -7.9929e-01,\n",
      "         7.5747e-01,  1.0800e-01,  8.4996e-01, -5.8571e-01,  2.5468e-02,\n",
      "        -1.6090e-01, -2.6403e-01,  1.0188e+00,  2.7263e-01,  8.5467e-01,\n",
      "         1.0964e-01,  3.9649e-01, -1.3945e+00,  3.4267e-02, -1.9285e-01,\n",
      "        -7.8558e-01, -3.4262e-01,  5.5844e-01, -8.8354e-01,  1.3605e-01,\n",
      "        -7.2615e-01,  1.3128e-01, -5.5057e-01, -1.9632e-01,  2.5091e-02,\n",
      "        -4.0413e-01,  2.1968e-01, -7.0688e-01, -6.5839e-01, -1.1737e-02,\n",
      "         3.0453e-01, -2.2627e-01, -3.5793e-01,  1.8675e-01,  4.6787e-01,\n",
      "         8.5676e-01,  1.2064e+00, -5.2217e-01, -6.3123e-01, -9.0002e-02,\n",
      "         1.6871e-01,  3.2400e-01,  5.3979e-01,  1.6413e-01, -7.6342e-01,\n",
      "         8.4849e-01,  1.1389e-01, -7.5328e-01,  1.9130e-01,  6.1746e-01,\n",
      "         6.8697e-01, -6.1561e-01, -1.4439e-01, -1.2929e-01,  1.2100e+00,\n",
      "         5.4743e-01, -1.2011e+00, -5.2297e-01,  6.9281e-01, -9.9156e-01,\n",
      "        -2.4302e-01, -1.2403e+00, -7.7784e-01, -7.6951e-01, -9.1110e-01,\n",
      "         3.9511e-02,  1.1298e+00,  7.0036e-01, -9.4394e-01, -3.0684e-01,\n",
      "         6.1110e-01, -3.9886e-01, -6.3806e-02,  1.0261e+00,  5.2469e-01,\n",
      "         7.4414e-02, -4.5932e-01,  5.5606e-01,  1.5858e+00, -5.0055e-01,\n",
      "         5.9638e-01, -4.5197e-01, -9.0242e-01,  3.4917e-01,  3.1038e-01,\n",
      "         2.1125e-01, -5.8735e-01, -1.4187e-02, -9.4114e-01, -1.1103e-01,\n",
      "        -4.9303e-01,  4.2970e-01,  1.0701e+00, -2.9947e-01, -5.9706e-02,\n",
      "         1.8423e-01, -1.8498e-01, -2.7651e-01, -3.0548e-01, -6.3188e-01,\n",
      "         2.6154e-01, -3.2580e-01, -2.5411e-01, -2.7256e-01, -5.8104e-01,\n",
      "        -5.0161e-01, -1.0549e-01,  6.9120e-01, -3.5367e-01,  8.6724e-01,\n",
      "        -6.2647e-01, -1.6546e+00, -2.1778e-02, -1.4282e-02, -8.7156e-01,\n",
      "        -6.9835e-01,  1.4126e-02,  1.3087e+00,  7.5469e-01, -1.6355e+00,\n",
      "         2.5660e-01, -7.6657e-01, -2.1407e-01,  1.1882e+00, -8.8778e-02,\n",
      "         3.1350e-01, -7.9428e-01,  1.2017e+00, -6.4122e-02,  6.6545e-01,\n",
      "        -4.0202e-01,  1.0122e-01, -1.3358e-01, -1.7409e-01, -3.8127e-01,\n",
      "         3.9576e-02,  8.0545e-01,  1.0116e+00, -6.4436e-01,  5.5998e-01,\n",
      "        -1.0792e+00,  2.2663e-01,  5.5942e-01, -5.3404e-01, -1.2129e+00,\n",
      "         1.1171e-01, -1.7187e-01,  6.2046e-01,  4.3970e-01, -1.2976e+00,\n",
      "         3.4084e-01, -1.1726e+00,  3.6148e-01, -3.7688e-01,  3.6031e-01,\n",
      "        -2.5291e-01, -8.0355e-01, -1.7270e-01, -3.5659e-01, -1.3702e+00,\n",
      "         3.9968e-01,  1.2177e+00,  6.7822e-01, -5.2303e-01, -6.4682e-01,\n",
      "        -2.3120e-02,  5.3442e-01, -5.3570e-01, -2.2924e-01,  1.1478e-01,\n",
      "         5.6771e-01,  6.5060e-01,  4.0460e-01, -1.6335e-01, -2.7604e-01,\n",
      "         4.1566e-01, -2.2424e-01,  4.5937e-01,  2.5394e-01,  5.5394e-02,\n",
      "         7.9278e-01, -8.0632e-01,  3.5483e-01, -1.9602e-01, -1.8726e-01,\n",
      "        -3.7245e-01,  9.6739e-01, -2.3522e-01, -7.1648e-01, -9.0153e-01,\n",
      "        -6.0121e-01, -1.0271e+00,  1.7828e-01, -9.0727e-01, -1.4506e-02,\n",
      "        -1.4445e+00,  3.9620e-01, -2.2443e-01, -4.1109e-02, -6.0587e-01,\n",
      "         9.3130e-01, -1.3173e+00,  9.9026e-02, -8.6742e-01,  1.4353e-03,\n",
      "         1.8551e-01, -1.0251e-01,  4.1711e-01, -1.9351e-01,  5.0945e-01,\n",
      "        -2.4243e-01, -1.4495e+00, -9.6205e-02,  2.3436e-01, -6.1643e-01,\n",
      "         1.5604e+00, -9.2837e-01, -3.8620e-01, -7.5645e-01, -1.0117e-01,\n",
      "         1.0445e+00, -2.2408e+00, -7.4022e-01,  8.0940e-02,  7.3965e-01,\n",
      "        -7.7772e-01,  9.5940e-01,  3.3307e-01,  1.0610e+00, -8.0016e-01,\n",
      "         1.1242e-01,  1.0064e+00,  2.6842e-01,  1.7452e+00, -6.6552e-01,\n",
      "         9.5580e-01,  3.7086e-01,  6.9490e-01, -1.0746e+00,  6.7507e-01,\n",
      "         2.9162e-01, -8.7129e-01,  8.0579e-01,  4.1294e-01,  6.8895e-01,\n",
      "        -1.0461e+00,  7.4662e-01,  9.7427e-01,  9.4851e-01,  2.3221e-01,\n",
      "        -9.4017e-01, -7.8059e-01, -2.9144e-01, -3.9741e-01, -1.4340e-01,\n",
      "        -4.2324e-01, -2.6035e-01, -2.2289e-01,  1.7065e-01,  1.9845e-01,\n",
      "         9.6862e-01, -6.3970e-01,  6.6832e-01, -6.0189e-01, -4.8989e-02,\n",
      "         2.4702e-01, -8.0388e-01, -1.0709e+00, -5.8767e-02,  8.9153e-01,\n",
      "        -1.1562e-01,  2.6761e-01, -7.4649e-01,  1.0233e+00,  1.3030e+00,\n",
      "         1.6774e-01, -1.3131e+00, -8.1963e-01,  7.6590e-03, -6.8577e-01,\n",
      "         3.3989e-01, -8.3189e-02,  1.7586e-01, -2.4241e-01, -6.0370e-01,\n",
      "         4.6332e-01,  1.7853e+00,  2.7684e-01])\n"
     ]
    }
   ],
   "source": [
    "interest_rep = torch.mean(torch.cat(final_reps), axis=0).squeeze(0)\n",
    "\n",
    "print(\"The shape of the final, aggregated vector is: {}\".format(interest_rep.shape))\n",
    "\n",
    "print(interest_rep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FO4n94GfPRNT"
   },
   "source": [
    "We can repeat this process for some other words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 876,
     "status": "ok",
     "timestamp": 1635956221615,
     "user": {
      "displayName": "Sandip Panesar",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03744674344979941942"
     },
     "user_tz": 420
    },
    "id": "7NILE5udPQXo"
   },
   "outputs": [],
   "source": [
    "# Lets make a helper function to make the process easier\n",
    "def encode_represent(batch, tokenizer, model, toi):\n",
    "  encoded_batch = [encode(example, tokenizer) for example in batch]\n",
    "  batch_reps = [represent(example, model, layer=1) for example in encoded_batch]\n",
    "  toi = encode(toi, tokenizer)\n",
    "  indices = [find_sublist_indices(toi, id.squeeze(0)) for id in encoded_batch]\n",
    "  final_reps = [rep.squeeze()[idx] for idx, rep in zip(indices, batch_reps)]\n",
    "  return torch.mean(torch.cat(final_reps), axis=0).squeeze(0)\n",
    "\n",
    "\n",
    "batch2 = ['the sky is blue',\n",
    "          'blue is the color of the ocean',\n",
    "          'she has blue eyes']\n",
    "\n",
    "blue_rep = encode_represent(batch2, tokenizer, model, 'blue')\n",
    "\n",
    "batch3 = ['i was so angry i was seeing red',\n",
    "          'he drives a red corvette',\n",
    "          'the girl in the red dress']\n",
    "\n",
    "red_rep = encode_represent(batch3, tokenizer, model, 'red')\n",
    "\n",
    "# And just for an example, lets create another batch for 'blue' but in a different context\n",
    "batch4 = ['blue cheese is a type of cheese',\n",
    "          'the presence of mold in the cheese gives it characteristic blue streaks',\n",
    "          'gorgonzola is a type of blue cheese',\n",
    "          'not everybody likes blue cheese due to its strong flavor and smell']\n",
    "\n",
    "blue2_rep = encode_represent(batch4, tokenizer, model, 'blue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UbqXKMEURj23"
   },
   "source": [
    "The above code will have generated two lists of contextual representations for each of the words of interest, i.e. 'blue' and 'red'. Then the mean of each of these was taken, yielding two aggregated word representations for each word. Subsequently, operations such as cosine similarity can be performed between these two tensor objects:\n",
    "\n",
    "$$\n",
    "\\mathrm{similarity(a, b)=cos(\\theta)=\\frac{a \\cdot b}{\\lVert a \\rVert \\lVert b \\rVert}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1635956221616,
     "user": {
      "displayName": "Sandip Panesar",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03744674344979941942"
     },
     "user_tz": 420
    },
    "id": "MEFu6uwNRTfZ",
    "outputId": "218218c9-d041-4526-8824-d2ec7ab2de12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between words 'blue' and 'red': 0.5347683429718018\n",
      "Similarity between words 'blue' and 'interest': 0.1250074803829193\n",
      "Similarity between words 'blue' and 'blue' in different contexts: 0.8751708269119263\n"
     ]
    }
   ],
   "source": [
    "cos_br = torch.dot(blue_rep, red_rep)/(torch.norm(blue_rep)*torch.norm(red_rep))\n",
    "print(\"Similarity between words 'blue' and 'red': {}\".format(cos_br))\n",
    "cos_bi = torch.dot(blue_rep, interest_rep)/(torch.norm(blue_rep)*torch.norm(interest_rep))\n",
    "print(\"Similarity between words 'blue' and 'interest': {}\".format(cos_bi))\n",
    "cos_bb = torch.dot(blue_rep, blue2_rep)/(torch.norm(blue_rep)*torch.norm(blue2_rep))\n",
    "print(\"Similarity between words 'blue' and 'blue' in different contexts: {}\".format(cos_bb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UBI4BOAEG8v8"
   },
   "source": [
    "Note how the similarity between 'blue' and 'red' is greater than the similarity between 'blue' and 'interest'. Note also how the similarity between 'blue,' albeit in different contexts, is almost 0.9.\n",
    "\n",
    "Here, we have described a process of aggregating several contextual examples for a particular word of interest. This single, aggregated example can be utilized in the same way as static word representations e.g. linear analogies etc. Moreover, taking the mean is only one way to aggregate the representations. Bommasani et al. (2020) tried various approaches including taking the maximum, minimum, first and last of the various contextual examples. \n",
    "\n",
    "**References**\n",
    "\n",
    "1. Mikolov, T., Chen, K., Corrado, G. and Dean, J., 2013. Efficient estimation of word representations in vector space. arXiv preprint arXiv:1301.3781.\n",
    "\n",
    "2. Pennington, J., Socher, R. and Manning, C.D., 2014, October. Glove: Global vectors for word representation. In Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP) (pp. 1532-1543).\n",
    "\n",
    "3. Bommasani, R., Davis, K. and Cardie, C., 2020, July. Interpreting pretrained contextualized representations via reductions to static embeddings. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics (pp. 4758-4781)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1635956221616,
     "user": {
      "displayName": "Sandip Panesar",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03744674344979941942"
     },
     "user_tz": 420
    },
    "id": "OizabGvd4bGp"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "contextual2static_for_students.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0251b88692df44688b0ff26d7629bed0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_273b0054e0834e50988a8bde13161295",
       "IPY_MODEL_799873ccb3a94dbeb9e9c604d03ecb35",
       "IPY_MODEL_b0b47f4343344ddf99559b27fab6fd5a"
      ],
      "layout": "IPY_MODEL_83dbd1c0361f43a888a4758027e99aab"
     }
    },
    "027144937cfe4cd3abaf4647b00c0fcf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "042fb908dfd64e6a80438ea57d18a2d7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "05a179a1cdc54420b2da841a25c3043c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0a19f9ec8f2746fb8805492fb8c2b285": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "12dd1ec1a7454c598f4002342074e7d6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f691f289f27942c38447c4d04b3b2018",
      "placeholder": "",
      "style": "IPY_MODEL_24cb537309e94aa993aa5d6ca1dd5b03",
      "value": " 455k/455k [00:00&lt;00:00, 987kB/s]"
     }
    },
    "1fadd47b94464b4fb5a099735683584d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7b88a40da21b42e7bf4e74955ec9f6a1",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c556dd714c474cf6961b8822d1c7dbd9",
      "value": 231508
     }
    },
    "24cb537309e94aa993aa5d6ca1dd5b03": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "273b0054e0834e50988a8bde13161295": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8aebd40abf70427791116f8a8e30851f",
      "placeholder": "",
      "style": "IPY_MODEL_2dbc2c66e1604bd5bc424fe29a5a2325",
      "value": "Downloading: 100%"
     }
    },
    "2aaacf29c21b4ccca8dafe9035d00fd2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2cf7b96360ae432ab536b0ac7823b9e2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_67c85c93aa584c38b236fc6fdeac5bc1",
      "placeholder": "",
      "style": "IPY_MODEL_cd305930f718415180560af0d26d4a00",
      "value": " 28.0/28.0 [00:00&lt;00:00, 635B/s]"
     }
    },
    "2dbc2c66e1604bd5bc424fe29a5a2325": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "33663a1580fe4a8385c1ba4fdc7e04de": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "409a36817c8a4e7f890a3d8bab688e20": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a7c1c93f69d34f829cbe9b5b99c3defc",
      "placeholder": "",
      "style": "IPY_MODEL_f654f4f436bd4c49a0a7d065127ce323",
      "value": "Downloading: 100%"
     }
    },
    "43781e9c6b7b4d91b7f0e6568da1c041": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "438b91bcadaa4857a07788ebea8a13df": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f31c5195de314354a9e95638577fa778",
      "placeholder": "",
      "style": "IPY_MODEL_ed1a761d1e374aecbb82bcfef8a692b9",
      "value": " 226k/226k [00:00&lt;00:00, 839kB/s]"
     }
    },
    "45ac8e1df7a34eee9597b1df0f02fb24": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_aed5f87365a649ce9d07241687cbc165",
      "max": 466062,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_db39f7b79f1d4abeae8725368c4d9df9",
      "value": 466062
     }
    },
    "4f0ece9b730e41329028b1c3337608cc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "52999766033741d9a81f4f9da7fd02d4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "67c85c93aa584c38b236fc6fdeac5bc1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7682e7c82b364d62a9fd9b19c496613f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "799873ccb3a94dbeb9e9c604d03ecb35": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_52999766033741d9a81f4f9da7fd02d4",
      "max": 440473133,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e5dae727f27f4984bd141abc20084657",
      "value": 440473133
     }
    },
    "7b88a40da21b42e7bf4e74955ec9f6a1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7e3222dc777f44b18bf780290d6b9d1d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_027144937cfe4cd3abaf4647b00c0fcf",
      "placeholder": "",
      "style": "IPY_MODEL_88689cf7a073423cb26025323811e642",
      "value": " 570/570 [00:00&lt;00:00, 9.43kB/s]"
     }
    },
    "83dbd1c0361f43a888a4758027e99aab": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "88689cf7a073423cb26025323811e642": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8a1b60947d964cb18ceffefb5997bf44": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8aebd40abf70427791116f8a8e30851f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "962625fe6a4e4c5ba2ddf870211eadb0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b1afee80bec8444bbcd0052e42ae07ec",
       "IPY_MODEL_cc12c8746ba44140ac8c976d5a23fecf",
       "IPY_MODEL_7e3222dc777f44b18bf780290d6b9d1d"
      ],
      "layout": "IPY_MODEL_e54f72015b224ffca8c69735cb481c29"
     }
    },
    "a17f97492e7d4840857fd45597fb5be6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_409a36817c8a4e7f890a3d8bab688e20",
       "IPY_MODEL_a339223d9c1647ceb9a1c5a43003ee95",
       "IPY_MODEL_2cf7b96360ae432ab536b0ac7823b9e2"
      ],
      "layout": "IPY_MODEL_05a179a1cdc54420b2da841a25c3043c"
     }
    },
    "a339223d9c1647ceb9a1c5a43003ee95": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7682e7c82b364d62a9fd9b19c496613f",
      "max": 28,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f8c5485b0f804c9991b708b6d1b3a09d",
      "value": 28
     }
    },
    "a7c1c93f69d34f829cbe9b5b99c3defc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "aa142709b85e4af28d9e6e419b8047c3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "aed5f87365a649ce9d07241687cbc165": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b0b47f4343344ddf99559b27fab6fd5a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f107bf601845471881c311dba80a844b",
      "placeholder": "",
      "style": "IPY_MODEL_eb9a5b0d5f7f45548005a1155cf3e237",
      "value": " 420M/420M [00:11&lt;00:00, 40.7MB/s]"
     }
    },
    "b1afee80bec8444bbcd0052e42ae07ec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_aa142709b85e4af28d9e6e419b8047c3",
      "placeholder": "",
      "style": "IPY_MODEL_8a1b60947d964cb18ceffefb5997bf44",
      "value": "Downloading: 100%"
     }
    },
    "b384376666b8470486fa3afb89d2e099": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b71875355fbf46f8966a73c58265f572": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bfef98f27ebd477c983b18f0ff10dfeb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fc237f5c0c53450a8effc8b23408d46d",
       "IPY_MODEL_45ac8e1df7a34eee9597b1df0f02fb24",
       "IPY_MODEL_12dd1ec1a7454c598f4002342074e7d6"
      ],
      "layout": "IPY_MODEL_33663a1580fe4a8385c1ba4fdc7e04de"
     }
    },
    "c4f02ef823a54284a4079774300d7dbe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2aaacf29c21b4ccca8dafe9035d00fd2",
      "placeholder": "",
      "style": "IPY_MODEL_b71875355fbf46f8966a73c58265f572",
      "value": "Downloading: 100%"
     }
    },
    "c556dd714c474cf6961b8822d1c7dbd9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "cc12c8746ba44140ac8c976d5a23fecf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b384376666b8470486fa3afb89d2e099",
      "max": 570,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0a19f9ec8f2746fb8805492fb8c2b285",
      "value": 570
     }
    },
    "cd305930f718415180560af0d26d4a00": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "db39f7b79f1d4abeae8725368c4d9df9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e38e12a9ed69438c9b773ad185765ca4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c4f02ef823a54284a4079774300d7dbe",
       "IPY_MODEL_1fadd47b94464b4fb5a099735683584d",
       "IPY_MODEL_438b91bcadaa4857a07788ebea8a13df"
      ],
      "layout": "IPY_MODEL_4f0ece9b730e41329028b1c3337608cc"
     }
    },
    "e54f72015b224ffca8c69735cb481c29": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e5dae727f27f4984bd141abc20084657": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "eb9a5b0d5f7f45548005a1155cf3e237": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ed1a761d1e374aecbb82bcfef8a692b9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f107bf601845471881c311dba80a844b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f31c5195de314354a9e95638577fa778": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f654f4f436bd4c49a0a7d065127ce323": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f691f289f27942c38447c4d04b3b2018": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f8c5485b0f804c9991b708b6d1b3a09d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "fc237f5c0c53450a8effc8b23408d46d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_042fb908dfd64e6a80438ea57d18a2d7",
      "placeholder": "",
      "style": "IPY_MODEL_43781e9c6b7b4d91b7f0e6568da1c041",
      "value": "Downloading: 100%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
